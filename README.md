# ðŸ›‘ Deprecated â€“ See New Version: [AirSeg](https://github.com/chetana348/AirSeg-Learnable-Interconnected-Attention-Framework-for-Robust-Airway-Segmentation)

---

## âš ï¸ Notice

This repository contains an **older version** of our airway segmentation model and is now **deprecated**.

For the latest version with improved performance, better generalization, and a learnable attention mechanism, please refer to our new repository:

ðŸ‘‰ **[AirSeg: Learnable Interconnected Attention Framework for Robust Airway Segmentation](https://github.com/chetana348/AirSeg-Learnable-Interconnected-Attention-Framework-for-Robust-Airway-Segmentation)**

---

## âœ… Why Keep This Repo?

While deprecated, this model:
- Remains fully functional
- Outperforms baseline models for lung segmentation
- Can serve as a **lightweight baseline**
- Offers a great **starting point** for airway segmentation tasks or model prototyping

> ðŸ’¡ Ideal for researchers who want to understand the foundations of the newer AirSeg architecture or build simpler extensions.

---

## ðŸ“Œ Overview

This model is designed for **segmentation of lungs and airways** from 3D chest CT scans.

Unlike traditional U-Net-based models, this approach is particularly effective at:

- Capturing **tiny, fragmented, or discontinuous airway branches**
- Preserving **fine structural details** in both proximal and distal airways
- Providing a more accurate and complete segmentation of the airway tree

> ðŸ« Ideal for applications in **pulmonary imaging**, **preoperative planning**, and **airway disease analysis**

---

## âš™ï¸ Installation

To set up the environment for this project, use the provided `environment.yml` file.

### ðŸ”§ Step-by-Step

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/your-repo-name.git
   cd your-repo-name
   ```

2. Create and activate the conda environment:
   ```bash
   conda env create -f environment.yml
   conda activate airway_segmentation_env
   ```

3. Ensure you have a compatible **GPU setup** for TensorFlow:
   - CUDA and cuDNN should match your TensorFlow GPU version
   - Recommended TensorFlow: `tensorflow-gpu >= 2.x`

> âš ï¸ This project is optimized for **TensorFlow GPU**. Using only CPU may result in significantly slower inference and training times.

---

## ðŸ“š Dataset & Model Weights

This model was originally trained on **proprietary chest CT datasets**. While the dataset is not publicly available, the model has shown strong **generalization to other CT datasets** with similar preprocessing.

### ðŸ”— Pretrained Weights

You can download the pretrained model weights from the following Google Drive link:

ðŸ“¦ [Model Weights â€“ Google Drive](https://drive.google.com/drive/folders/1H1QUAC9UnkFKWtnHB_wgukHdUJREbNCa)

These weights can be used directly for inference or fine-tuning on custom datasets.

---

## ðŸ§ª Preprocessing Pipeline

To prepare your CT scans for training or inference, follow these steps:

1. **Resize** all slices to `128 Ã— 128` pixels  
2. **Slice** 3D volumes into individual 2D axial slices  
3. **Normalize** intensity values to the range `[0, 1]` or `[0, 255]` depending on the model input expectations

> âš ï¸ Ensure consistent spacing and alignment across datasets for optimal performance.

---

## ðŸ“ Repository Structure

Below is an overview of the key files and folders in this repository:

```
â”œâ”€â”€ Networks/                         # Model architecture scripts and building blocks
â”œâ”€â”€ saved/                            # Folder containing pretrained model weights
â”‚
â”œâ”€â”€ 1. Pre-Processing.ipynb           # Resize, slice, and normalize CT images
â”œâ”€â”€ 2. Train_Prediction_Evaluation.ipynb  # Full pipeline for training, inference, and evaluation
â”œâ”€â”€ Only predictions.ipynb           # Inference-only notebook using pretrained weights
â”‚
â”œâ”€â”€ Functions_Airways1.ipynb         # Postprocessing and visualization for airway segmentation
â”œâ”€â”€ Functions_Lungs1.ipynb           # Postprocessing and visualization for lung segmentation
â”‚
â”œâ”€â”€ Data_Gen_2D.py                   # Data generator for 2D image slices
â”œâ”€â”€ switchnorm.py                    # Custom normalization layer (SwitchNorm)
â”‚
â”œâ”€â”€ environment.yml                  # Conda environment file with all dependencies
â”œâ”€â”€ .gitattributes                   # Git configuration
â”œâ”€â”€ SOP.pptx                         # Presentation showing step-by step to run
â”œâ”€â”€ README.md                        # You are here ðŸ“„
```

> ðŸ“¦ **Note:** Pretrained model weights are located in the `saved/` directory and can be loaded directly in the notebooks.

---

## ðŸ§ª Try It in Google Colab

Want to try the model without setting up your local environment?

You can test the full pipeline â€” including preprocessing, prediction, and visualization â€” using our **Colab notebook**:

ðŸ”— **[Run in Google Colab](https://drive.google.com/drive/folders/1SBL6bOjsyhwK8Ib5fgrQa4Zr8peVuYXn?usp=sharing)**

> ðŸ“¦ The notebook is preconfigured to load the pretrained weights and sample data.  
> Make sure to mount your Google Drive when prompted and follow the step-by-step cells.

---

## ðŸ“„ License

This project is licensed under the **MIT License**.

